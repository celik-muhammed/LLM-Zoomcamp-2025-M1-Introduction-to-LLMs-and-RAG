{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7392f0ab",
   "metadata": {},
   "source": [
    "<!-- +----------------+-----------------------------+--------------------------+\n",
    "| Tool           | Description                 | Best Use Case            |\n",
    "+================+=============================+==========================+\n",
    "| Anaconda       | Full Python data distro     | Beginner-friendly setup  |\n",
    "+----------------+-----------------------------+--------------------------+\n",
    "| Miniconda      | Minimal Conda installer     | Custom, lightweight envs |\n",
    "+----------------+-----------------------------+--------------------------+\n",
    "| Micromamba     | Fast Conda alternative      | CI/CD, containers        |\n",
    "+----------------+-----------------------------+--------------------------+ -->\n",
    "\n",
    "| Tool        | Description                                           | Best Use Case             | Size (initial)        | Download Link                                                                 |\n",
    "|-------------|-------------------------------------------------------|---------------------------|------------------------|--------------------------------------------------------------------------------|\n",
    "| Anaconda    | Full Python data distro                               | Beginner-friendly setup   | ðŸš› Huge (~3â€“5 GB)      | [Archive ðŸ“¦](https://repo.anaconda.com/archive/)                               |\n",
    "| Miniconda   | Minimal Conda installer (Python + conda)              | Custom, lightweight envs  | ðŸ“¦ Small (~70 MB)      | [Miniconda Releases ðŸŒ](https://repo.anaconda.com/miniconda/)                 |\n",
    "| Micromamba  | Fast, lightweight Conda-compatible CLI (C++ binary)   | CI/CD, containers         | ðŸª¶ Tiny (~2 MB binary) | [Micromamba GitHub ðŸš€](https://github.com/mamba-org/micromamba-releases/tags) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39855d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd07cf",
   "metadata": {},
   "source": [
    "## openai key \n",
    "\n",
    "- [platform.openai.com](https://platform.openai.com/docs/overview)\n",
    "- https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f9b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm notebook jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f782523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai transformers tensorflow tf-keras elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5ccae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e82b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "\n",
    "# Securely prompt user for Hugging Face token (input will be hidden)\n",
    "# token = getpass.getpass(\"ðŸ” Enter your Hugging Face token: \").strip()\n",
    "\n",
    "# Validate token is not empty\n",
    "# if not token:\n",
    "#     raise ValueError(\"âš ï¸ Token input was empty. Please enter a valid token.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea72fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the token from environment variable\n",
    "# os.environ[\"HUGGINGFACE_TOKEN\"]\n",
    "# os.environ.get(\"HUGGINGFACE_TOKEN\", None)\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ef1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Perform login â€“ this stores the token in your local cache securely\n",
    "login(token=token)\n",
    "\n",
    "# print(\"âœ… Successfully logged in to Hugging Face Hub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405a3384-0d9b-4941-8200-59c99c2637dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  â€œOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDonâ€™t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5383c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 16:11:37.355160: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-01 16:11:37.375177: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-01 16:11:37.638701: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-01 16:11:37.799342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751386298.106584  111229 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751386298.204014  111229 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751386298.862870  111229 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751386298.862918  111229 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751386298.862922  111229 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751386298.862924  111229 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-01 16:11:38.907913: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Device set to use cpu\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th Jan 2024\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "result = qa({\n",
    "    \"context\": documents[0]['text'],\n",
    "    \"question\": documents[0]['question']\n",
    "})\n",
    "\n",
    "print(result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39fdd6",
   "metadata": {},
   "source": [
    "## Elasticsearch, Inside Codespaces to Docker\n",
    "\n",
    "- https://hub.docker.com/_/elasticsearch/tags\n",
    "\n",
    "ðŸ”Ž Explanation:\n",
    "- xpack.security.enabled=false: disables security for quick testing\n",
    "- discovery.type=single-node: prevents bootstrap checks\n",
    "- elasticsearch:9.0.2: use official image from docker.elastic.co\n",
    "\n",
    "```sh\n",
    "docker ps\n",
    "docker pull \"elasticsearch:9.0.2\"\n",
    "\n",
    "docker run -d -p 9200:9200 -e \"discovery.type=single-node\" \"elasticsearch:9.0.2\"\n",
    "\n",
    "docker run -d --name es-dev \\\n",
    "  -p 9200:9200 \\\n",
    "  -p 9300:9300 \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:9.0.2\n",
    "```\n",
    "\n",
    "Open Kibana in your browser:\n",
    "- http://localhost:5601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081013bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docker-compose.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker-compose.yml\n",
    "\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "\n",
    "  elasticsearch:\n",
    "    image: docker.elastic.co/elasticsearch/elasticsearch:9.0.2\n",
    "    container_name: es-dev\n",
    "    environment:\n",
    "      - discovery.type=single-node\n",
    "      - xpack.security.enabled=false         # disable auth\n",
    "      - ES_JAVA_OPTS=-Xms512m -Xmx512m       # lower heap for dev use\n",
    "    ports:\n",
    "      - \"9200:9200\"\n",
    "    volumes:\n",
    "      - esdata:/usr/share/elasticsearch/data\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"curl -s http://localhost:9200 >/dev/null || exit 1\"]\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  kibana:\n",
    "    image: docker.elastic.co/kibana/kibana:9.0.2\n",
    "    container_name: kibana\n",
    "    environment:\n",
    "      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n",
    "      - xpack.security.enabled=false\n",
    "    ports:\n",
    "      - \"5601:5601\"\n",
    "    depends_on:\n",
    "      elasticsearch:\n",
    "        condition: service_healthy\n",
    "\n",
    "volumes:\n",
    "  esdata:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50368b29-f5a2-4c73-b52f-798e38973242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bfa398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d2dc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '2ccf31400ab2', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'ijKUPCs6S4m7q9woeGo4dA', 'version': {'number': '9.0.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '0a58bc1dc7a4ae5412db66624aab968370bd44ce', 'build_date': '2025-05-28T10:06:37.834829258Z', 'build_snapshot': False, 'lucene_version': '10.1.0', 'minimum_wire_compatibility_version': '8.18.0', 'minimum_index_compatibility_version': '8.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e9f7256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"2ccf31400ab2\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"ijKUPCs6S4m7q9woeGo4dA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"9.0.2\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"0a58bc1dc7a4ae5412db66624aab968370bd44ce\",\n",
      "    \"build_date\" : \"2025-05-28T10:06:37.834829258Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"10.1.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"8.18.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"8.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df6c8319-3d03-48f0-b6f3-58c7a9c67fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "332e49da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'course-questions' already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "if not es_client.indices.exists(index=index_name):\n",
    "    es_client.indices.create(index=index_name, body=index_settings)\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists, skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b1be47-06e4-4cd5-a6ec-cf92e9aa805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb40249b-9848-4a74-bc63-b652b1d3b8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eea1214e44e4804894989b1a1fd0b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fab4329-8230-4aca-b233-791442016072",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do execute a command on a Kubernetes pod?\"\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "search_results = es_client.search(index=index_name, body=search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ef01df1-283a-4140-aa05-bb0c0be1e58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.56891"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results['hits']['hits'][0]['_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b26c1ca-b921-4886-8b52-432017d4a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do copy a file to a Docker container?\"\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"machine-learning-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "search_results = es_client.search(index=index_name, body=search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "377acaea-3752-43ce-b1d2-88845e3897b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'course-questions',\n",
       "  '_id': 'ORK0xpcB5pkhxiHVtT0Y',\n",
       "  '_score': 73.5441,\n",
       "  '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': '7RK4xpcB5pkhxiHVeUAr',\n",
       "  '_score': 73.5441,\n",
       "  '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}},\n",
       " {'_index': 'course-questions',\n",
       "  '_id': 'oRLCxpcB5pkhxiHVVERY',\n",
       "  '_score': 73.5441,\n",
       "  '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ef298ee-70cc-4083-ab77-19f9d665bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "163fa4c5-1822-4770-8cdc-3614ddc359af",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_pieces = []\n",
    "\n",
    "for hit in search_results['hits']['hits']:\n",
    "    doc = hit['_source']\n",
    "    context_piece = context_template.format(**doc)\n",
    "    context_pieces.append(context_piece)\n",
    "\n",
    "context = '\\n\\n'.join(context_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b5712cf-1b45-4a56-a7e2-8ff81dc850de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=query, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e92826bc-1d93-43a4-8c2c-8483009a6494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a605729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21bacfbd-b152-4173-8d03-055d5938cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acae2085-c2d6-4e1f-98ce-3f039e2b3ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "442be939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m tiktoken.encoding_for_model(model_name: \u001b[33m'str'\u001b[39m) -> \u001b[33m'Encoding'\u001b[39m\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m encoding_for_model(model_name: str) -> Encoding:\n",
      "    \u001b[33m\"\"\"Returns the encoding used by a model.\u001b[39m\n",
      "\n",
      "\u001b[33m    Raises a KeyError if the model name is not recognised.\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m get_encoding(encoding_name_for_model(model_name))\n",
      "\u001b[31mFile:\u001b[39m      /usr/local/python/3.12.1/lib/python3.12/site-packages/tiktoken/model.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "tiktoken.encoding_for_model??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d512c5f2-3c73-4006-9b26-76819b88e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding = tiktoken.encoding_for_model(\"gpt-4o\")  # openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccc14410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "encoding = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")  # hf\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18fb5d96-f44a-4e7b-b076-97d390fedf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdc331b5-a6a8-47ce-8769-bde1e71ee0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1185, 214, 10, 768, 5307, 3167, 4, 31652, 5]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = encoding.encode(prompt)[:10]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc0b5407-bccb-4e5a-8a6d-bd787c0d13f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' teaching'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding.decode_single_token_bytes(tokens[5])  # openai\n",
    "encoding.decode(tokens[5])  # hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a66a30-38eb-4c9d-9fb1-e053335cde9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
